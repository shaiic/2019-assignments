{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "file_name = \"D:\\\\ch04.npz\"\n",
    "class SimpleDataReader(object):\n",
    "    def __init__(self):\n",
    "        self.train_file_name = file_name\n",
    "        self.num_train = 0\n",
    "        self.XTrain = None\n",
    "        self.YTrain = None\n",
    "\n",
    "    # read data from file\n",
    "    def ReadData(self):\n",
    "        train_file = Path(self.train_file_name)\n",
    "        if train_file.exists():\n",
    "            data = np.load(self.train_file_name)\n",
    "            self.XTrain = data[\"data\"]\n",
    "            self.YTrain = data[\"label\"]\n",
    "            self.num_train = self.XTrain.shape[0]\n",
    "        else:\n",
    "            raise Exception(\"Cannot find train file!!!\")\n",
    "        #end if\n",
    "\n",
    "    # get batch training data\n",
    "    def GetSingleTrainSample(self, iteration):\n",
    "        x = self.XTrain[iteration]\n",
    "        y = self.YTrain[iteration]\n",
    "        return x, y\n",
    "\n",
    "    # get batch training data\n",
    "    def GetBatchTrainSamples(self, batch_size, iteration):\n",
    "        start = iteration * batch_size\n",
    "        end = start + batch_size\n",
    "        batch_X = self.XTrain[start:end,:]\n",
    "        batch_Y = self.YTrain[start:end,:]\n",
    "        return batch_X, batch_Y\n",
    "\n",
    "    def GetWholeTrainSamples(self):\n",
    "        return self.XTrain, self.YTrain\n",
    "\n",
    "\n",
    "    # permutation only affect along the first axis, so we need transpose the array first\n",
    "    # see the comment of this class to understand the data format\n",
    "    def Shuffle(self):\n",
    "        seed = np.random.randint(0,100)\n",
    "        np.random.seed(seed)\n",
    "        XP = np.random.permutation(self.XTrain)\n",
    "        np.random.seed(seed)\n",
    "        YP = np.random.permutation(self.YTrain)\n",
    "        self.XTrain = XP\n",
    "        self.YTrain = YP\n",
    "\n",
    "class HyperParameters(object):\n",
    "    def __init__(self, input_size, output_size, eta=0.1, max_epoch=1000, batch_size=5, eps=0.1):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.eta = eta\n",
    "        self.max_epoch = max_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.eps = eps\n",
    "\n",
    "    def toString(self):\n",
    "        title = str.format(\"in:{0},out:{1},bz:{2},eta:{3}\", self.input_size, self.output_size, self.batch_size, self.eta)\n",
    "        return title\n",
    "\n",
    "class NeuralNet(object):\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.W = np.zeros((self.params.input_size, self.params.output_size))\n",
    "        self.B = np.zeros((1, self.params.output_size))\n",
    "\n",
    "    def __forwardBatch(self, batch_x):\n",
    "        Z = np.dot(batch_x, self.W) + self.B\n",
    "        return Z\n",
    "\n",
    "    def __backwardBatch(self, batch_x, batch_y, batch_z):\n",
    "        m = batch_x.shape[0]\n",
    "        dZ = batch_z - batch_y\n",
    "        dB = dZ.sum(axis=0, keepdims=True)/m\n",
    "        dW = np.dot(batch_x.T, dZ)/m\n",
    "        return dW, dB\n",
    "\n",
    "    def __update(self, dW, dB):\n",
    "        self.W = self.W - self.params.eta * dW\n",
    "        self.B = self.B - self.params.eta * dB\n",
    "\n",
    "    def inference(self, x):\n",
    "        return self.__forwardBatch(x)\n",
    "\n",
    "    def train(self, dataReader):\n",
    "        # calculate loss to decide the stop condition\n",
    "        loss_history = TrainingHistory()\n",
    "\n",
    "        if self.params.batch_size == -1:\n",
    "            self.params.batch_size = dataReader.num_train\n",
    "        max_iteration = (int)(dataReader.num_train / self.params.batch_size)\n",
    "        for epoch in range(self.params.max_epoch):\n",
    "            print(\"epoch=%d\" %epoch)\n",
    "            dataReader.Shuffle()\n",
    "            for iteration in range(max_iteration):\n",
    "                # get x and y value for one sample\n",
    "                batch_x, batch_y = dataReader.GetBatchTrainSamples(self.params.batch_size, iteration)\n",
    "                # get z from x,y\n",
    "                batch_z = self.__forwardBatch(batch_x)\n",
    "                # calculate gradient of w and b\n",
    "                dW, dB = self.__backwardBatch(batch_x, batch_y, batch_z)\n",
    "                # update w,b\n",
    "                self.__update(dW, dB)\n",
    "                if iteration % 2 == 0:\n",
    "                    loss = self.__checkLoss(dataReader)\n",
    "                    print(epoch, iteration, loss)\n",
    "                    loss_history.AddLossHistory(epoch*max_iteration+iteration, loss, self.W[0,0], self.B[0,0])\n",
    "                    if loss < self.params.eps:\n",
    "                        break\n",
    "                    #end if\n",
    "                #end if\n",
    "            # end for\n",
    "            if loss < self.params.eps:\n",
    "                break\n",
    "        # end for\n",
    "        loss_history.ShowLossHistory(self.params)\n",
    "        print(self.W, self.B)\n",
    "   \n",
    "        self.loss_contour(dataReader, loss_history, self.params.batch_size, epoch*max_iteration+iteration)\n",
    "\n",
    "    def __checkLoss(self, dataReader):\n",
    "        X,Y = dataReader.GetWholeTrainSamples()\n",
    "        m = X.shape[0]\n",
    "        Z = self.__forwardBatch(X)\n",
    "        LOSS = (Z - Y)**2\n",
    "        loss = LOSS.sum()/m/2\n",
    "        return loss\n",
    "\n",
    "    def loss_contour(self, dataReader,loss_history,batch_size,iteration):\n",
    "        last_loss, result_w, result_b = loss_history.GetLast()\n",
    "        X,Y=dataReader.GetWholeTrainSamples()\n",
    "        len1 = 50\n",
    "        len2 = 50\n",
    "        w = np.linspace(result_w-1,result_w+1,len1)\n",
    "        b = np.linspace(result_b-1,result_b+1,len2)\n",
    "        W,B = np.meshgrid(w,b)\n",
    "        len = len1 * len2\n",
    "        X,Y = dataReader.GetWholeTrainSamples()\n",
    "        m = X.shape[0]\n",
    "        Z = np.dot(X, W.ravel().reshape(1,len)) + B.ravel().reshape(1,len)\n",
    "        Loss1 = (Z - Y)**2\n",
    "        Loss2 = Loss1.sum(axis=0,keepdims=True)/m\n",
    "        Loss3 = Loss2.reshape(len1, len2)\n",
    "        plt.contour(W,B,Loss3,levels=np.logspace(-5, 5, 100), norm=LogNorm(), cmap=plt.cm.jet)\n",
    "\n",
    "        # show w,b trace\n",
    "        w_history = loss_history.w_history\n",
    "        b_history = loss_history.b_history\n",
    "        plt.plot(w_history,b_history)\n",
    "        plt.xlabel(\"w\")\n",
    "        plt.ylabel(\"b\")\n",
    "        title = str.format(\"batchsize={0}, iteration={1}, w={2:.3f}, b={3:.3f}\", batch_size, iteration, result_w, result_b)\n",
    "        plt.title(title)\n",
    "\n",
    "        plt.axis([result_w-1,result_w+1,result_b-1,result_b+1])\n",
    "        plt.show()\n",
    "\n",
    "class TrainingHistory(object):\n",
    "    def __init__(self):\n",
    "        self.iteration = []\n",
    "        self.loss_history = []\n",
    "        self.w_history = []\n",
    "        self.b_history = []\n",
    "\n",
    "    def AddLossHistory(self, iteration, loss, w, b):\n",
    "        self.iteration.append(iteration)\n",
    "        self.loss_history.append(loss)\n",
    "        self.w_history.append(w)\n",
    "        self.b_history.append(b)\n",
    "\n",
    "    def ShowLossHistory(self, params, xmin=None, xmax=None, ymin=None, ymax=None):\n",
    "        plt.plot(self.iteration, self.loss_history)\n",
    "        title = params.toString()\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        if xmin != None and ymin != None:\n",
    "            plt.axis([xmin, xmax, ymin, ymax])\n",
    "        plt.show()\n",
    "        return title\n",
    "\n",
    "    def GetLast(self):\n",
    "        count = len(self.loss_history)\n",
    "        return self.loss_history[count-1], self.w_history[count-1], self.b_history[count-1]\n",
    "# end class\n",
    "\n",
    "class LogicNotGateDataReader(SimpleDataReader):\n",
    "    # x=0,y=1; x=1,y=0\n",
    "    def ReadData(self):\n",
    "        X = np.array([0,1]).reshape(2,1)\n",
    "        Y = np.array([1,0]).reshape(2,1)\n",
    "        self.XTrain = X\n",
    "        self.YTrain = Y\n",
    "        self.num_train = 2\n",
    "\n",
    "\n",
    "def Test(net):\n",
    "    z1 = net.inference(0)\n",
    "    z2 = net.inference(1)\n",
    "    print (z1,z2)\n",
    "    if np.abs(z1-1) < 0.001 and np.abs(z2-0)<0.001:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def ShowResult(net):\n",
    "    x = np.array([-0.5,0,1,1.5]).reshape(4,1)\n",
    "    y = net.inference(x)\n",
    "    plt.plot(x,y)\n",
    "    plt.scatter(0,1,marker='^')\n",
    "    plt.scatter(1,0,marker='o')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     # read data\n",
    "    sdr = LogicNotGateDataReader()\n",
    "    sdr.ReadData()\n",
    "    # create net\n",
    "    params = HyperParameters(1,1,eta=0.1, max_epoch=1000, batch_size=1, eps = 1e-8)\n",
    "    net = NeuralNet(params)\n",
    "    net.train(sdr)\n",
    "    # result\n",
    "    print(\"w=%f,b=%f\" %(net.W, net.B))\n",
    "    # predication\n",
    "    print(Test(net))\n",
    "    ShowResult(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
