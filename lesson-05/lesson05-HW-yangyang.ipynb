{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "# Licensed under the MIT license. See LICENSE file in the project root for full license information.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from pathlib import Path\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "file_name = \"./ch05.npz\"\n",
    "\n",
    "class SimpleDataReader(object):\n",
    "    def __init__(self):\n",
    "        self.train_file_name = file_name\n",
    "        self.num_train = 0\n",
    "        self.XTrain = None  # normalized x, if not normalized, same as YRaw\n",
    "        self.YTrain = None  # normalized y, if not normalized, same as YRaw\n",
    "        self.XRaw = None    # raw x\n",
    "        self.YRaw = None    # raw y\n",
    "\n",
    "    # read data from file\n",
    "    def ReadData(self):\n",
    "        train_file = Path(self.train_file_name)\n",
    "        if train_file.exists():\n",
    "            data = np.load(self.train_file_name)\n",
    "            self.XRaw = data[\"data\"]\n",
    "            self.YRaw = data[\"label\"]\n",
    "            self.num_train = self.XRaw.shape[0]\n",
    "            self.XTrain = self.XRaw\n",
    "            self.YTrain = self.YRaw\n",
    "        else:\n",
    "            raise Exception(\"Cannot find train file!!!\")\n",
    "        #end if\n",
    "\n",
    "    def NormalizeX(self):\n",
    "        X_new = np.zeros(self.XRaw.shape)\n",
    "        num_feature = self.XRaw.shape[1]\n",
    "        self.X_norm = np.zeros((num_feature,2))\n",
    "        for i in range(num_feature):\n",
    "            # get one feature from all examples\n",
    "            col_i = self.XRaw[:,i]\n",
    "            max_value = np.max(col_i)\n",
    "            min_value = np.min(col_i)\n",
    "            # min value\n",
    "            self.X_norm[i,0] = min_value\n",
    "            # range value\n",
    "            self.X_norm[i,1] = max_value - min_value\n",
    "            new_col = (col_i - self.X_norm[i,0])/(self.X_norm[i,1])\n",
    "            X_new[:,i] = new_col\n",
    "        #end for\n",
    "        self.XTrain = X_new\n",
    "\n",
    "    # normalize data by self range and min_value\n",
    "    def NormalizePredicateData(self, X_raw):\n",
    "        X_new = np.zeros(X_raw.shape)\n",
    "        n = X_raw.shape[1]\n",
    "        for i in range(n):\n",
    "            col_i = X_raw[:,i]\n",
    "            X_new[:,i] = (col_i - self.X_norm[i,0]) / self.X_norm[i,1]\n",
    "        return X_new\n",
    "\n",
    "    def NormalizeY(self):\n",
    "        self.Y_norm = np.zeros((1,2))\n",
    "        max_value = np.max(self.YRaw)\n",
    "        min_value = np.min(self.YRaw)\n",
    "        # min value\n",
    "        self.Y_norm[0, 0] = min_value\n",
    "        # range value\n",
    "        self.Y_norm[0, 1] = max_value - min_value\n",
    "        y_new = (self.YRaw - min_value) / self.Y_norm[0, 1]\n",
    "        self.YTrain = y_new\n",
    "\n",
    "    # get batch training data\n",
    "    def GetSingleTrainSample(self, iteration):\n",
    "        x = self.XTrain[iteration]\n",
    "        y = self.YTrain[iteration]\n",
    "        return x, y\n",
    "\n",
    "    # get batch training data\n",
    "    def GetBatchTrainSamples(self, batch_size, iteration):\n",
    "        start = iteration * batch_size\n",
    "        end = start + batch_size\n",
    "        batch_X = self.XTrain[start:end,:]\n",
    "        batch_Y = self.YTrain[start:end,:]\n",
    "        return batch_X, batch_Y\n",
    "\n",
    "    def GetWholeTrainSamples(self):\n",
    "        return self.XTrain, self.YTrain\n",
    "\n",
    "    # permutation only affect along the first axis, so we need transpose the array first\n",
    "    # see the comment of this class to understand the data format\n",
    "    def Shuffle(self):\n",
    "        seed = np.random.randint(0,100)\n",
    "        np.random.seed(seed)\n",
    "        XP = np.random.permutation(self.XTrain)\n",
    "        np.random.seed(seed)\n",
    "        YP = np.random.permutation(self.YTrain)\n",
    "        self.XTrain = XP\n",
    "        self.YTrain = YP\n",
    "\n",
    "class HyperParameters(object):\n",
    "    def __init__(self, input_size, output_size, eta=0.1, max_epoch=1000, batch_size=5, eps=0.1):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.eta = eta\n",
    "        self.max_epoch = max_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.eps = eps\n",
    "\n",
    "    def toString(self):\n",
    "        title = str.format(\"bz:{0},eta:{1}\", self.batch_size, self.eta)\n",
    "        return title\n",
    "\n",
    "class TrainingHistory(object):\n",
    "    def __init__(self):\n",
    "        self.iteration = []\n",
    "        self.loss_history = []\n",
    "        self.w_history = []\n",
    "        self.b_history = []\n",
    "\n",
    "    def AddLossHistory(self, iteration, loss):\n",
    "        self.iteration.append(iteration)\n",
    "        self.loss_history.append(loss)\n",
    "        #self.w_history.append(w)\n",
    "        #self.b_history.append(b)\n",
    "\n",
    "    def ShowLossHistory(self, params, xmin=None, xmax=None, ymin=None, ymax=None):\n",
    "        plt.plot(self.iteration, self.loss_history)\n",
    "        title = params.toString()\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        if xmin != None and ymin != None:\n",
    "            plt.axis([xmin, xmax, ymin, ymax])\n",
    "        plt.show()\n",
    "        return title\n",
    "\n",
    "    def GetLast(self):\n",
    "        count = len(self.loss_history)\n",
    "        return self.loss_history[count-1], self.w_history[count-1], self.b_history[count-1]\n",
    "# end class\n",
    "\n",
    "class NeuralNet(object):\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.W = np.zeros((self.params.input_size, self.params.output_size))\n",
    "        self.B = np.zeros((1, self.params.output_size))\n",
    "\n",
    "    def __forwardBatch(self, batch_x):\n",
    "        Z = np.dot(batch_x, self.W) + self.B\n",
    "        return Z\n",
    "\n",
    "    def __backwardBatch(self, batch_x, batch_y, batch_z):\n",
    "        m = batch_x.shape[0]\n",
    "        dZ = batch_z - batch_y\n",
    "        dB = dZ.sum(axis=0, keepdims=True)/m\n",
    "        dW = np.dot(batch_x.T, dZ)/m\n",
    "        return dW, dB\n",
    "\n",
    "    def __update(self, dW, dB):\n",
    "        self.W = self.W - self.params.eta * dW\n",
    "        self.B = self.B - self.params.eta * dB\n",
    "\n",
    "    def inference(self, x):\n",
    "        return self.__forwardBatch(x)\n",
    "\n",
    "    def train(self, dataReader, checkpoint=0.1):\n",
    "        # calculate loss to decide the stop condition\n",
    "        loss_history = TrainingHistory()\n",
    "        loss = 10\n",
    "        if self.params.batch_size == -1:\n",
    "            self.params.batch_size = dataReader.num_train\n",
    "        max_iteration = math.ceil(dataReader.num_train / self.params.batch_size)\n",
    "        checkpoint_iteration = (int)(max_iteration * checkpoint)\n",
    "\n",
    "        for epoch in range(self.params.max_epoch):\n",
    "            print(\"epoch=%d\" %epoch)\n",
    "            dataReader.Shuffle()\n",
    "            for iteration in range(max_iteration):\n",
    "                # get x and y value for one sample\n",
    "                batch_x, batch_y = dataReader.GetBatchTrainSamples(self.params.batch_size, iteration)\n",
    "                # get z from x,y\n",
    "                batch_z = self.__forwardBatch(batch_x)\n",
    "                # calculate gradient of w and b\n",
    "                dW, dB = self.__backwardBatch(batch_x, batch_y, batch_z)\n",
    "                # update w,b\n",
    "                self.__update(dW, dB)\n",
    "\n",
    "                total_iteration = epoch * max_iteration + iteration\n",
    "                if (total_iteration+1) % checkpoint_iteration == 0:\n",
    "                    loss = self.__checkLoss(dataReader)\n",
    "                    print(epoch, iteration, loss, self.W, self.B)\n",
    "                    loss_history.AddLossHistory(epoch*max_iteration+iteration, loss)\n",
    "                    if loss < self.params.eps:\n",
    "                        break\n",
    "                    #end if\n",
    "                #end if\n",
    "            # end for\n",
    "            if loss < self.params.eps:\n",
    "                break\n",
    "        # end for\n",
    "        loss_history.ShowLossHistory(self.params)\n",
    "        print(\"W=\", self.W)\n",
    "        print(\"B=\", self.B)\n",
    "\n",
    "    def __checkLoss(self, dataReader):\n",
    "        X,Y = dataReader.GetWholeTrainSamples()\n",
    "        m = X.shape[0]\n",
    "        Z = self.__forwardBatch(X)\n",
    "        LOSS = (Z - Y)**2\n",
    "        loss = LOSS.sum()/m/2\n",
    "        return loss\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # data\n",
    "    reader = SimpleDataReader()\n",
    "    reader.ReadData()\n",
    "    reader.NormalizeX()\n",
    "    # net\n",
    "    params = HyperParameters(2, 1, eta=0.01, max_epoch=100, batch_size=10, eps = 1e-5)\n",
    "    net = NeuralNet(params)\n",
    "    net.train(reader, checkpoint=0.1)\n",
    "    # inference\n",
    "    x1 = 15\n",
    "    x2 = 93\n",
    "    x = np.array([x1,x2]).reshape(1,2)\n",
    "    x_new = reader.NormalizePredicateData(x)\n",
    "    z = net.inference(x_new)\n",
    "    print(\"Z=\", z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
